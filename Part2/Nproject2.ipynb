{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRWA Project Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Name | Email | UPF uNum |\n",
    "| --- | --- | --- |\n",
    "| Clara Pena | clara.pena01@estudiant.upf.edu | u186416 |\n",
    "| Yuyan Wang | yuyan.wang01@estudiant.upf.edu | u199907 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk import PorterStemmer, word_tokenize, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy.linalg as la\n",
    "import string\n",
    "import textwrap\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117405 entries, 0 to 117404\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        117405 non-null  int64 \n",
      " 1   content   117404 non-null  object\n",
      " 2   date      117405 non-null  object\n",
      " 3   hashtags  116794 non-null  object\n",
      " 4   likes     117405 non-null  int64 \n",
      " 5   retweets  117405 non-null  int64 \n",
      " 6   url       117405 non-null  object\n",
      " 7   language  117405 non-null  object\n",
      " 8   docId     48427 non-null   object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/processed_data.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with those tweets that have a document ID associated with them; that is, the value in the docID column should not be NaN. This is basically taking those tweets in English. Besides that, for simplicity, we're not using the column language anymore, so it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = df.dropna(subset=['docId']).drop(columns=['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>url</th>\n",
       "      <th>docId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1364506167226032128</td>\n",
       "      <td>watch full video farmersprotest nofarmersnofood tcofustokocxk</td>\n",
       "      <td>2021-02-24T09:23:16+00:00</td>\n",
       "      <td>#farmersprotest #NoFarmersNoFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/1364506167226032128</td>\n",
       "      <td>doc_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1364505991887347714</td>\n",
       "      <td>watch full video farmersprotest nofarmersnofood</td>\n",
       "      <td>2021-02-24T09:22:34+00:00</td>\n",
       "      <td>#farmersprotest #NoFarmersNoFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/1364505991887347714</td>\n",
       "      <td>doc_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1364505813834989568</td>\n",
       "      <td>watch full video farmersprotest nofarmersnofood</td>\n",
       "      <td>2021-02-24T09:21:51+00:00</td>\n",
       "      <td>#farmersprotest #NoFarmersNoFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/1364505813834989568</td>\n",
       "      <td>doc_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1364505749359976448</td>\n",
       "      <td>anoth farmer malkeet singh mahilpur hoshiarpur pass away delhi protest site farmersprotest</td>\n",
       "      <td>2021-02-24T09:21:36+00:00</td>\n",
       "      <td>#FarmersProtest</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>https://twitter.com/ShariaActivist/status/1364505749359976448</td>\n",
       "      <td>doc_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1364505676375076867</td>\n",
       "      <td>hi tell boss modidontsellfarm thank farmersprotest</td>\n",
       "      <td>2021-02-24T09:21:19+00:00</td>\n",
       "      <td>#ModiDontSellFarmers #FarmersProtest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/KaurDosanjh1979/status/1364505676375076867</td>\n",
       "      <td>doc_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1364505511073300481</td>\n",
       "      <td>watch full video farmersprotest nofarmersnofood</td>\n",
       "      <td>2021-02-24T09:20:39+00:00</td>\n",
       "      <td>#farmersprotest #NoFarmersNoFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/1364505511073300481</td>\n",
       "      <td>doc_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1364505452134817795</td>\n",
       "      <td>despit increas tax petroldiesel must increas tax alcohol cigarett tobacco aatamnirbhartbharat kissabl petrolpricehik petrolpric modihaitomehngaihai bjp farmersprotest</td>\n",
       "      <td>2021-02-24T09:20:25+00:00</td>\n",
       "      <td>#taxes #petrolDiesel #taxes #alcohol #cigarettes #tobacco #aatamnirbhartbharat #Kissables #PetrolPriceHike #PetrolPrice #ModiHaiToMehngaiHai #modi_rojgaar_दो #BJP #FarmersProtest #Budget2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://twitter.com/Satende09192805/status/1364505452134817795</td>\n",
       "      <td>doc_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1364505443997937669</td>\n",
       "      <td>mockeri menac sedit charg farmersprotest</td>\n",
       "      <td>2021-02-24T09:20:23+00:00</td>\n",
       "      <td>#sedition #FarmersProtest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/algo_121/status/1364505443997937669</td>\n",
       "      <td>doc_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1364505314586951680</td>\n",
       "      <td>watch full video farmersprotest nofarmersnofood</td>\n",
       "      <td>2021-02-24T09:19:52+00:00</td>\n",
       "      <td>#farmersprotest #NoFarmersNoFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/1364505314586951680</td>\n",
       "      <td>doc_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1364505255946379268</td>\n",
       "      <td>left hear modi lol farmersprotest</td>\n",
       "      <td>2021-02-24T09:19:38+00:00</td>\n",
       "      <td>#FarmersProtest</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/kdhanjal12/status/1364505255946379268</td>\n",
       "      <td>doc_11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  \\\n",
       "1   1364506167226032128   \n",
       "6   1364505991887347714   \n",
       "9   1364505813834989568   \n",
       "10  1364505749359976448   \n",
       "14  1364505676375076867   \n",
       "16  1364505511073300481   \n",
       "18  1364505452134817795   \n",
       "20  1364505443997937669   \n",
       "25  1364505314586951680   \n",
       "26  1364505255946379268   \n",
       "\n",
       "                                                                                                                                                                   content  \\\n",
       "1                                                                                                            watch full video farmersprotest nofarmersnofood tcofustokocxk   \n",
       "6                                                                                                                          watch full video farmersprotest nofarmersnofood   \n",
       "9                                                                                                                          watch full video farmersprotest nofarmersnofood   \n",
       "10                                                                              anoth farmer malkeet singh mahilpur hoshiarpur pass away delhi protest site farmersprotest   \n",
       "14                                                                                                                      hi tell boss modidontsellfarm thank farmersprotest   \n",
       "16                                                                                                                         watch full video farmersprotest nofarmersnofood   \n",
       "18  despit increas tax petroldiesel must increas tax alcohol cigarett tobacco aatamnirbhartbharat kissabl petrolpricehik petrolpric modihaitomehngaihai bjp farmersprotest   \n",
       "20                                                                                                                                mockeri menac sedit charg farmersprotest   \n",
       "25                                                                                                                         watch full video farmersprotest nofarmersnofood   \n",
       "26                                                                                                                                       left hear modi lol farmersprotest   \n",
       "\n",
       "                         date  \\\n",
       "1   2021-02-24T09:23:16+00:00   \n",
       "6   2021-02-24T09:22:34+00:00   \n",
       "9   2021-02-24T09:21:51+00:00   \n",
       "10  2021-02-24T09:21:36+00:00   \n",
       "14  2021-02-24T09:21:19+00:00   \n",
       "16  2021-02-24T09:20:39+00:00   \n",
       "18  2021-02-24T09:20:25+00:00   \n",
       "20  2021-02-24T09:20:23+00:00   \n",
       "25  2021-02-24T09:19:52+00:00   \n",
       "26  2021-02-24T09:19:38+00:00   \n",
       "\n",
       "                                                                                                                                                                                          hashtags  \\\n",
       "1                                                                                                                                                                 #farmersprotest #NoFarmersNoFood   \n",
       "6                                                                                                                                                                 #farmersprotest #NoFarmersNoFood   \n",
       "9                                                                                                                                                                 #farmersprotest #NoFarmersNoFood   \n",
       "10                                                                                                                                                                                 #FarmersProtest   \n",
       "14                                                                                                                                                            #ModiDontSellFarmers #FarmersProtest   \n",
       "16                                                                                                                                                                #farmersprotest #NoFarmersNoFood   \n",
       "18  #taxes #petrolDiesel #taxes #alcohol #cigarettes #tobacco #aatamnirbhartbharat #Kissables #PetrolPriceHike #PetrolPrice #ModiHaiToMehngaiHai #modi_rojgaar_दो #BJP #FarmersProtest #Budget2021   \n",
       "20                                                                                                                                                                       #sedition #FarmersProtest   \n",
       "25                                                                                                                                                                #farmersprotest #NoFarmersNoFood   \n",
       "26                                                                                                                                                                                 #FarmersProtest   \n",
       "\n",
       "    likes  retweets  \\\n",
       "1       0         0   \n",
       "6       0         0   \n",
       "9       0         0   \n",
       "10      3         3   \n",
       "14      0         0   \n",
       "16      0         0   \n",
       "18      1         1   \n",
       "20      0         0   \n",
       "25      0         0   \n",
       "26      1         0   \n",
       "\n",
       "                                                               url   docId  \n",
       "1     https://twitter.com/anmoldhaliwal/status/1364506167226032128   doc_2  \n",
       "6     https://twitter.com/anmoldhaliwal/status/1364505991887347714   doc_3  \n",
       "9     https://twitter.com/anmoldhaliwal/status/1364505813834989568   doc_4  \n",
       "10   https://twitter.com/ShariaActivist/status/1364505749359976448   doc_5  \n",
       "14  https://twitter.com/KaurDosanjh1979/status/1364505676375076867   doc_6  \n",
       "16    https://twitter.com/anmoldhaliwal/status/1364505511073300481   doc_7  \n",
       "18  https://twitter.com/Satende09192805/status/1364505452134817795   doc_8  \n",
       "20         https://twitter.com/algo_121/status/1364505443997937669   doc_9  \n",
       "25    https://twitter.com/anmoldhaliwal/status/1364505314586951680  doc_10  \n",
       "26       https://twitter.com/kdhanjal12/status/1364505255946379268  doc_11  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48427 entries, 1 to 117404\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        48427 non-null  int64 \n",
      " 1   content   48427 non-null  object\n",
      " 2   date      48427 non-null  object\n",
      " 3   hashtags  48153 non-null  object\n",
      " 4   likes     48427 non-null  int64 \n",
      " 5   retweets  48427 non-null  int64 \n",
      " 6   url       48427 non-null  object\n",
      " 7   docId     48427 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(df):\n",
    "    index = defaultdict(list)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        doc_id = row['docId']\n",
    "        terms = row['content'].split()\n",
    "        \n",
    "        current_page_index = {}\n",
    "        for position, term in enumerate(terms):\n",
    "            if term in current_page_index:\n",
    "                current_page_index[term][1].append(position)\n",
    "            else:\n",
    "                current_page_index[term] = [doc_id, array('I', [position])]  # 'I' for array of unsigned ints.\n",
    "\n",
    "        # Merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = create_index(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30477\n"
     ]
    }
   ],
   "source": [
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, lang_code='en', language_mapping={'en': 'english', 'es': 'spanish', 'fr': 'french', 'de': 'german', 'da': 'danish', 'nl': 'dutch', 'it': 'italian', 'fi': 'finnish', 'ru': 'russian', 'el': 'greek', 'no': 'norwegian', 'pt': 'portuguese', 'sv': 'swedish'}):\n",
    "    # Map language code to SnowballStemmer language name\n",
    "    language = language_mapping.get(lang_code, \"english\")  # Default to 'english' if lang_code is unsupported\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove mentions (anything starting with @ and followed by any characters until a space or end of the string)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "\n",
    "    # Handle contractions by removing possessive endings and common contractions\n",
    "    text = re.sub(r\"\\b(\\w+)'s\\b\", r'\\1', text)  # Changes \"people's\" to \"people\"\n",
    "    text = re.sub(r\"\\b(\\w+)n't\\b\", r'\\1 not', text)  # Changes \"isn't\" to \"is not\"\n",
    "    text = re.sub(r\"\\b(\\w+)'ll\\b\", r'\\1 will', text)  # Changes \"I'll\" to \"I will\"\n",
    "    text = re.sub(r\"\\b(\\w+)'d\\b\", r'\\1 would', text)  # Changes \"I'd\" to \"I would\"\n",
    "    text = re.sub(r\"\\b(\\w+)'re\\b\", r'\\1 are', text)  # Changes \"you're\" to \"you are\"\n",
    "    text = re.sub(r\"\\b(\\w+)'ve\\b\", r'\\1 have', text)  # Changes \"I've\" to \"I have\"\n",
    "\n",
    "    tokens = word_tokenize(text, language=language)\n",
    "\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped_tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "    # Remove non-alphabetic tokens\n",
    "    words = [word for word in stripped_tokens if word.isalpha()]\n",
    "\n",
    "    # Remove stop words for the detected language\n",
    "    try:\n",
    "        stop_words = set(stopwords.words(language))\n",
    "        stop_words.add('https')\n",
    "    except OSError:\n",
    "        stop_words = set()\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    # print(\"------------- WORDS\", words)\n",
    "    # Stemming\n",
    "    try:\n",
    "        stemmer = SnowballStemmer(language)\n",
    "        stemmed = stemmer.stem(' '.join(words))\n",
    "    except Exception as e:\n",
    "        print(f\"Stemming not performed due to: {e}\")\n",
    "        stemmed = words  # Fallback to non-stemmed words if stemming fails\n",
    "\n",
    "\n",
    "    # print(\"------------- HERE\", stemmed.split())\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_terms(line):\n",
    "    # stemmer = PorterStemmer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.lower()\n",
    "    line = line.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    line = [w.translate(table) for w in line]\n",
    "    line = [w for w in line if w not in stop_words]\n",
    "    line = [stemmer.stem(w) for w in line] \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, index):\n",
    "    query = preprocess_text(query)  # Normalize and tokenize the query.\n",
    "    docs = None  # Initialize docs as None to handle the intersection.\n",
    "\n",
    "    for term in query:\n",
    "        try:\n",
    "            # Extract the document IDs for the term.\n",
    "            term_docs = set([posting[0] for posting in index[term]])\n",
    "\n",
    "            if docs is None:\n",
    "                # Initialize docs with the set of document IDs for the first term.\n",
    "                docs = term_docs\n",
    "            else:\n",
    "                # Intersect the sets of document IDs.\n",
    "                docs = docs.intersection(term_docs)\n",
    "        except KeyError:\n",
    "            # If the term is not in the index, return an empty list because no documents can satisfy the query.\n",
    "            return []\n",
    "\n",
    "    if docs is None:\n",
    "        return []  # If no terms were processed, return an empty list.\n",
    "    else:\n",
    "        return list(docs)  # Convert the set to a list before returning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('farmersprotest', 50272), ('farmer', 17421), ('india', 7724), ('support', 6004), ('protest', 4787), ('amp', 4728), ('right', 3594), ('peopl', 3526), ('modi', 3113), ('indian', 3008), ('govern', 2753), ('bjp', 2649), ('law', 2570), ('releasedetainedfarm', 2432), ('govt', 2338), ('stand', 2207), ('farmersmakeindia', 2133), ('indiabeingsilenc', 2133), ('thank', 2129), ('farm', 2066)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the top n terms in the DataFrame for the specified column.\n",
    "def get_top_terms(df, column='content', top_n=10):\n",
    "    text = ' '.join(df[column].dropna())  # Combine all text and convert to lower case.\n",
    "    words = text.split()\n",
    "    # Get a count of all words\n",
    "    word_count = Counter(words)\n",
    "    # Return the most common words\n",
    "    return word_count.most_common(top_n)\n",
    "\n",
    "top_terms = get_top_terms(tweets_df, column='content', top_n=20)\n",
    "print(top_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* “farmers protest India”: This query integrates the most frequent term ‘farmersprotest’ with ‘India’, capturing a broad perspective of the geographical context. It is designed to test the engine’s capability to fetch documents that discuss the nationwide impact and scale of the protests. The inclusion of ‘India’ helps to ensure that the search results are not just about protests in general but specifically about the farmers’ protests within the Indian context.\n",
    "\t\n",
    "* “support farmer rights”: By combining ‘support’ with ‘farmer’ and ‘rights’, this query delves into the solidarity and advocacy aspects surrounding the protests. It focuses on the socio-political dimensions of the farmers’ rights being debated or upheld. This query is intended to evaluate how well the search engine can identify and retrieve content that discusses support mechanisms, both local and global, for the farmers amidst the protests.\n",
    "\t\n",
    "* “Modi government response”: Including ‘Modi’ and ‘government’ targets discussions related to the administrative and political response to the protests. Given that government actions and policies are central to the unfolding of the protests, this query checks the engine’s effectiveness in pulling up content that critically examines or reports on the government’s strategies and reactions, providing a lens into the political narrative.\n",
    "\t\n",
    "* “BJP agricultural laws”: Merging ‘BJP’ with ‘laws’ specifically focuses on the political party in power and the controversial agricultural laws that sparked the protests. This query is crafted to test the search engine’s precision in sifting through discussions related to legislative actions and political affiliations that are pivotal to understanding the core issues of the protests. It aims to highlight documents that discuss the legal frameworks and political viewpoints that define the conflict.\n",
    "\t\n",
    "* “Indian farmers rally”: This query combines ‘Indian’ with ‘farmers’ and adds a dynamic aspect with ‘rally’, pointing to organized protest events. It is designed to retrieve documents that detail specific events, their significance, and the participation dynamics during the protests. This tests the search engine’s ability to focus on event-based reporting and narratives that capture the mobilization and active participation of the farming community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- WORDS ['farmers', 'protest', 'india']\n",
      "------------- HERE ['farmers', 'protest', 'india']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'farmers protest India':\n",
      "\n",
      "------------- WORDS ['support', 'farmer', 'rights']\n",
      "------------- HERE ['support', 'farmer', 'right']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'support farmer rights':\n",
      "\n",
      "------------- WORDS ['modi', 'government', 'response']\n",
      "------------- HERE ['modi', 'government', 'respons']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'Modi government response':\n",
      "\n",
      "------------- WORDS ['bjp', 'agricultural', 'laws']\n",
      "------------- HERE ['bjp', 'agricultural', 'law']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'BJP agricultural laws':\n",
      "\n",
      "------------- WORDS ['indian', 'farmers', 'rally']\n",
      "------------- HERE ['indian', 'farmers', 'r']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'Indian farmers rally':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simulate_search(queries, index):\n",
    "    for query in queries:\n",
    "        docs = search(query, index)\n",
    "        top = 10  # Number of results to display\n",
    "        num_results = len(docs)\n",
    "        \n",
    "        print(\"\\n======================\\nSample of {} results out of {} for the searched query '{}':\\n\".format(min(top, num_results), num_results, query))\n",
    "        for d_id in docs[:top]:\n",
    "            print(\"docId = {}\".format(d_id))\n",
    "\n",
    "# List of queries to be processed\n",
    "queries = [\n",
    "    \"farmers protest India\",\n",
    "    \"support farmer rights\",\n",
    "    \"Modi government response\",\n",
    "    \"BJP agricultural laws\",\n",
    "    \"Indian farmers rally\"\n",
    "]\n",
    "\n",
    "simulate_search(queries, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tfidf(dataframe):\n",
    "    # num_documents = len(df)\n",
    "    num_documents = dataframe['docId'].nunique()\n",
    "    index = defaultdict(list)\n",
    "    # tf = defaultdict(dict)  # Normalized term frequencies of terms in documents\n",
    "    tf = defaultdict(list)\n",
    "    df = defaultdict(int)  # Document frequencies of terms\n",
    "    idf = defaultdict(float)\n",
    "\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        doc_id = row['docId']\n",
    "        terms = row['content'].split()\n",
    "        \n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms):\n",
    "            if term in current_page_index:\n",
    "                # Append the position to the corresponding list in the array\n",
    "                current_page_index[term][1].append(position)\n",
    "            else:\n",
    "                # Initialize the list with page_id and a new array\n",
    "                current_page_index[term] = [doc_id, array('I', [position])]\n",
    "\n",
    "        # Calculate the norm for the terms in the document\n",
    "        norm = math.sqrt(sum(len(positions[1])**2 for positions in current_page_index.values()))\n",
    "\n",
    "        # calculate the tf(dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in current_page_index.items():\n",
    "            # append the tf for current term (tf = term frequency in current doc/norm)\n",
    "            tf[term].append(np.round(len(posting[1])/norm,4)) ## SEE formula (1) above\n",
    "            #increment the document frequency of current term (number of documents containing the current term)\n",
    "            df[term] += 1 # increment DF for current term\n",
    "        \n",
    "        # Merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "    # Calculate IDF for each term\n",
    "    for term in df:\n",
    "        idf[term] = math.log(num_documents / (1 + df[term]))  # Smoothing by adding 1 to denominator\n",
    "\n",
    "    return index, tf, df, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, tf, df, idf = create_index_tfidf(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Arguments:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    \n",
    "    Returns:\n",
    "    List of ranked documents based on the relevance\n",
    "    \"\"\"\n",
    "    doc_vectors = defaultdict(lambda: np.zeros(len(terms)))\n",
    "    query_vector = np.zeros(len(terms))\n",
    "    query_terms_count = Counter(terms)\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    # Compute the tf-idf for the query vector\n",
    "    for term_index, term in enumerate(terms):\n",
    "        if term in idf:\n",
    "            query_vector[term_index] = query_terms_count[term] / query_norm * idf[term]\n",
    "            if term not in index:\n",
    "                continue\n",
    "    \n",
    "            for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "                if doc in docs:\n",
    "                    doc_vectors[doc][term_index] = tf[term][doc_index] * idf[term]  # T\n",
    "            \n",
    "    # Calculate the score of each doc using cosine similarity (dot product of normalized vectors)\n",
    "    doc_scores = [[np.dot(cur_doc_vec, query_vector), doc] for doc, cur_doc_vec in doc_vectors.items()]\n",
    "    doc_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    # print(doc_scores)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "    else:\n",
    "        return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Output is the list of documents that contain all of the query terms. \n",
    "    This requires taking the intersection of the lists of documents for each query term.\n",
    "    \"\"\"\n",
    "    query = preprocess_text(query)\n",
    "    # print(query)\n",
    "    docs = None  # Initialize to None to handle the first term's document set initialization\n",
    "\n",
    "    for term in query:\n",
    "        if term in index:\n",
    "            term_docs = set([posting[0] for posting in index[term]])  # Collect all document IDs containing this term\n",
    "            if docs is None:\n",
    "                docs = term_docs\n",
    "            else:\n",
    "                docs = docs.intersection(term_docs)  # Intersection with the accumulated set of documents\n",
    "        else:\n",
    "            return []  # If any term is not found, the intersection is empty\n",
    "\n",
    "    if docs is None:\n",
    "        return []  # No terms found, return empty list\n",
    "\n",
    "    docs = list(docs)  # Convert set to list if necessary\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)  # Rank the documents based on the relevance\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_search_tf_idf(queries, index, idf, tf):\n",
    "    for query in queries:\n",
    "        ranked_docs = search_tf_idf(query, index, idf, tf)\n",
    "        top = 10  # Number of results to display\n",
    "        num_results = len(ranked_docs)\n",
    "        \n",
    "        print(\"\\n======================\\nSample of {} results out of {} for the searched query '{}':\\n\".format(min(top, num_results), num_results, query))\n",
    "        for d_id in ranked_docs[:top]:\n",
    "            print(\"docId = {}\".format(d_id))\n",
    "\n",
    "# List of queries to be processed\n",
    "queries = [\n",
    "    \"farmers protest India\",\n",
    "    \"support farmer rights\",\n",
    "    \"Modi government response\",\n",
    "    \"BJP agricultural laws\",\n",
    "    \"Indian farmers rally\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- WORDS ['farmers', 'protest', 'india']\n",
      "------------- HERE ['farmers', 'protest', 'india']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'farmers protest India':\n",
      "\n",
      "------------- WORDS ['support', 'farmer', 'rights']\n",
      "------------- HERE ['support', 'farmer', 'right']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'support farmer rights':\n",
      "\n",
      "------------- WORDS ['modi', 'government', 'response']\n",
      "------------- HERE ['modi', 'government', 'respons']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'Modi government response':\n",
      "\n",
      "------------- WORDS ['bjp', 'agricultural', 'laws']\n",
      "------------- HERE ['bjp', 'agricultural', 'law']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'BJP agricultural laws':\n",
      "\n",
      "------------- WORDS ['indian', 'farmers', 'rally']\n",
      "------------- HERE ['indian', 'farmers', 'r']\n",
      "\n",
      "======================\n",
      "Sample of 0 results out of 0 for the searched query 'Indian farmers rally':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulate_search_tf_idf(queries, index, idf, tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_gt = pd.read_csv('./data/evaluation_gt.csv', sep=';')\n",
    "df_eva = pd.merge(tweets_df, evaluation_gt, on='docId', how='left')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "query_1_relevant = (df_eva[(df_eva['query_id'] == 1) & (df_eva['label'] == 1)])['docId'].unique()\n",
    "query_1_not_relevant = (df_eva[(df_eva['query_id'] == 1) & (df_eva['label'] == 0)])['docId'].unique()\n",
    "\n",
    "query_2_relevant = (df_eva[(df_eva['query_id'] == 2) & (df_eva['label'] == 1)])['docId'].unique()\n",
    "query_2_not_relevant = (df_eva[(df_eva['query_id'] == 2) & (df_eva['label'] == 0)])['docId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that for the evaluation part we will be using only the subset of documents that are being defined in the evaluation_gt.csv\n",
    "df_subset_documents = df_eva[df_eva['query_id'].notnull()]\n",
    "subset_documents = df_subset_documents['docId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, tf, df, idf = create_index_tfidf(df_subset_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- WORDS ['people', 'rights']\n",
      "------------- HERE ['people', 'right']\n",
      "------------- WORDS ['indian', 'government']\n",
      "------------- HERE ['indian', 'govern']\n"
     ]
    }
   ],
   "source": [
    "query_1_results = search_tf_idf(\"people rights\", index, idf, tf)\n",
    "query_2_results = search_tf_idf(\"Indian government\", index, idf, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- WORDS ['people', 'rights']\n",
      "------------- HERE ['people', 'right']\n"
     ]
    }
   ],
   "source": [
    "out = preprocess_text(\"people's rights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- WORDS ['indian', 'government']\n",
      "------------- HERE ['indian', 'govern']\n"
     ]
    }
   ],
   "source": [
    "out = preprocess_text(\"Indian government?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowball Stemmer: \n",
      "people right\n",
      "peopl\n",
      "right\n",
      "Porter Stemmer: \n",
      "what is being said about the indian govern\n",
      "what\n",
      "is\n",
      "be\n",
      "said\n",
      "about\n",
      "the\n",
      "indian\n",
      "govern\n"
     ]
    }
   ],
   "source": [
    "print(\"Snowball Stemmer: \")\n",
    "stem = SnowballStemmer(\"english\")\n",
    "print(stem.stem(\"people rights\"))\n",
    "for w in [\"people\", \"rights\"]:\n",
    "    print(stem.stem(w))\n",
    "\n",
    "print(\"Porter Stemmer: \")\n",
    "stem = PorterStemmer()\n",
    "print(stem.stem(\"what is being said about the Indian government\"))\n",
    "for w in [\"what\", \"is\", \"being\", \"said\", \"about\", \"the\", \"Indian\", \"government\"]:\n",
    "    print(stem.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Files Query 1 (subset): ['doc_1047' 'doc_2100' 'doc_3287' 'doc_3474' 'doc_3570' 'doc_4053'\n",
      " 'doc_5480' 'doc_5512' 'doc_5751' 'doc_6477' 'doc_8066' 'doc_9696'\n",
      " 'doc_9850' 'doc_9937' 'doc_10048']\n",
      "\n",
      "Our Obtained Results Query 1: []\n",
      "\n",
      "Ground Truth Files Query 2 (subset): ['doc_103' 'doc_1566' 'doc_1651' 'doc_1666' 'doc_1785' 'doc_2528'\n",
      " 'doc_2653' 'doc_3005' 'doc_3076' 'doc_3116' 'doc_3646' 'doc_3682'\n",
      " 'doc_3927' 'doc_4176' 'doc_4304']\n",
      "\n",
      "Our Obtained Results Query 2: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_wrapped(title, data):\n",
    "    wrapper = textwrap.TextWrapper(width=90)\n",
    "    wrapped_text = wrapper.fill(str(data))\n",
    "    print(f\"{title} {wrapped_text}\\n\")\n",
    "\n",
    "print(f\"Ground Truth Files Query 1 (subset): {query_1_relevant}\\n\")\n",
    "print_wrapped(\"Our Obtained Results Query 1:\", query_1_results)\n",
    "\n",
    "print(f\"Ground Truth Files Query 2 (subset): {query_2_relevant}\\n\")\n",
    "print_wrapped(\"Our Obtained Results Query 2:\", query_2_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
